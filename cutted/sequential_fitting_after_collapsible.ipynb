{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coefficients are now spherical expansion coefficients for H centered environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 10, 6, 11)\n"
     ]
    }
   ],
   "source": [
    "print(coefficients.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the first steps from standar sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_0, odd_0 = InitialTransformer().transform(coefficients)\n",
    "initial_pca = IndividualLambdaPCAsBoth()\n",
    "initial_pca.fit(even_0, odd_0)\n",
    "even_0_t, odd_0_t = initial_pca.transform(even_0, odd_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit couple of standard blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_1 = StandardBlock(ThresholdExpansioner(100), None, IndividualLambdaPCAsBoth(20))\n",
    "block_1.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "even_1, odd_1, _ = block_1.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "\n",
    "block_2 = StandardBlock(None, None, None, ThresholdExpansioner(100, mode = 'invariants'))\n",
    "block_2.fit(even_1, odd_1, even_0_t, odd_0_t)\n",
    "_, _, even_invariants = block_2.transform(even_1, odd_1, even_0_t, odd_0_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At his moment we have all parts of this standard sequence fitted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nice = StandardSequence(initial_pca= initial_pca, blocks = [block_1, block_2])\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what about full model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(nice.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. \n",
    "\n",
    "At this point there is very high probability to make a mistake. Particularly one can feed StandardSequence with some fitted initial_pca along with blocks, which were fitted based not on the same initial_pca, or with different initial_normalizer, or even on different data. In order to prevent it, there is requirement to pass additional flag guaranteed_parts_fitted_consistently = True to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "nice = StandardSequence(initial_pca= initial_pca, blocks = [block_1, block_2],\n",
    "                         guaranteed_parts_fitted_consistently = True)\n",
    "print(nice.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is considered to be fitted if 1) all parts are fitted and 2) if guaranteed_parts_fitted_consistently is set to be True\n",
    "\n",
    "**Golden rule:** Every time you pass guaranteed_parts_fitted_consistently = True make a pause and think twice. \n",
    "\n",
    "Let's check consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "even_invariants_2 = nice.transform(coefficients, return_only_invariants = True)[3]\n",
    "print(np.sum(np.abs(even_invariants - even_invariants_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works in other direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "initial_pca = IndividualLambdaPCAsBoth()\n",
    "block_1 = StandardBlock(ThresholdExpansioner(100), None, IndividualLambdaPCAsBoth(20))\n",
    "block_2 = StandardBlock(None, None, None, ThresholdExpansioner(100, mode = 'invariants'))\n",
    "\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())\n",
    "\n",
    "nice = StandardSequence(initial_pca = initial_pca, blocks = [block_1, block_2])\n",
    "nice.fit(coefficients)\n",
    "\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardBlock behaves the same way:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n",
    "print(expansioner.is_fitted())\n",
    "print(pca.is_fitted())\n",
    "\n",
    "block = StandardBlock(expansioner, None, pca)\n",
    "block.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "\n",
    "print(expansioner.is_fitted())\n",
    "print(pca.is_fitted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n",
    "expansioner.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "even_1, odd_1 = expansioner.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "pca.fit(even_1, odd_1)\n",
    "\n",
    "block = StandardBlock(expansioner, None, pca, \n",
    "                      guaranteed_parts_fitted_consistently = True)\n",
    "\n",
    "print(block.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another group of blocks, which accepts classes such as sklearn.linear_model.Ridge in the initialization. But in their case there is need to apply several distinct regressors, separatelly for each lambda channel and parity. Thus, input regressor is clonned, and initial instances is not touched in any way. So, the material of this tutorials does not apply to purifiers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
