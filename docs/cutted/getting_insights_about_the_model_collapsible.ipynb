{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# cell to wrap in collapsible in future\n", "\n", "# downloading dataset from https://archive.materialscloud.org/record/2020.110\n", "\n", "!wget \"https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\" -O methane.extxyz.gz\n", "!gunzip -k methane.extxyz.gz\n", "\n", "import numpy as np\n", "import ase.io\n", "import tqdm\n", "from nice.blocks import *\n", "from nice.utilities import *\n", "from matplotlib import pyplot as plt\n", "from sklearn.linear_model import BayesianRidge\n", "\n", "HARTREE_TO_EV = 27.211386245988\n", "train_subset = \"0:10000\"  #input for ase.io.read command\n", "test_subset = \"10000:15000\"  #input to ase.io.read command\n", "environments_for_fitting = 1000  #number of environments to fit nice transfomers\n", "grid = [150, 200, 350, 500, 750, 1000, 1500, 2000, 3000, 5000, 7500,\n", "        10000]  #for learning curve\n", "\n", "#HYPERS for librascal spherical expansion coefficients\n", "HYPERS = {\n", "    'interaction_cutoff': 6.3,\n", "    'max_radial': 5,\n", "    'max_angular': 5,\n", "    'gaussian_sigma_type': 'Constant',\n", "    'gaussian_sigma_constant': 0.05,\n", "    'cutoff_smooth_width': 0.3,\n", "    'radial_basis': 'GTO'\n", "}\n", "\n", "\n", "#our model:\n", "def get_nice():\n", "    return StandardSequence([\n", "        StandardBlock(ThresholdExpansioner(num_expand=150),\n", "                      CovariantsPurifierBoth(max_take=10),\n", "                      IndividualLambdaPCAsBoth(n_components=50),\n", "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n", "                      InvariantsPurifier(max_take=50),\n", "                      InvariantsPCA(n_components=200)),\n", "        StandardBlock(ThresholdExpansioner(num_expand=150),\n", "                      CovariantsPurifierBoth(max_take=10),\n", "                      IndividualLambdaPCAsBoth(n_components=50),\n", "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n", "                      InvariantsPurifier(max_take=50),\n", "                      InvariantsPCA(n_components=200)),\n", "        StandardBlock(ThresholdExpansioner(num_expand=150),\n", "                      CovariantsPurifierBoth(max_take=10),\n", "                      IndividualLambdaPCAsBoth(n_components=50),\n", "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n", "                      InvariantsPurifier(max_take=50),\n", "                      InvariantsPCA(n_components=200))\n", "    ],\n", "                            initial_scaler=InitialScaler(\n", "                                mode='signal integral', individually=True))\n", "\n", "\n", "train_structures = ase.io.read('methane.extxyz', index=train_subset)\n", "\n", "test_structures = ase.io.read('methane.extxyz', index=test_subset)\n", "\n", "all_species = get_all_species(train_structures + test_structures)\n", "\n", "train_coefficients = get_spherical_expansion(train_structures, HYPERS,\n", "                                             all_species)\n", "\n", "test_coefficients = get_spherical_expansion(test_structures, HYPERS,\n", "                                            all_species)\n", "\n", "#individual nice transformers for each atomic specie in the dataset\n", "nice = {}\n", "for key in train_coefficients.keys():\n", "    nice[key] = get_nice()\n", "\n", "for key in train_coefficients.keys():\n", "    nice[key].fit(train_coefficients[key][:environments_for_fitting])"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 4}