{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["coefficients are now spherical expansion coefficients for H centered environments:"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["(4000, 10, 6, 11)\n"]}], "source": ["print(coefficients.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's do the first steps from standar sequence:"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["even_0, odd_0 = InitialTransformer().transform(coefficients)\n", "initial_pca = IndividualLambdaPCAsBoth()\n", "initial_pca.fit(even_0, odd_0)\n", "even_0_t, odd_0_t = initial_pca.transform(even_0, odd_0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can fit couple of standard blocks:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["block_1 = StandardBlock(ThresholdExpansioner(100), None,\n", "                        IndividualLambdaPCAsBoth(20))\n", "block_1.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n", "even_1, odd_1, _ = block_1.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n", "\n", "block_2 = StandardBlock(None, None, None,\n", "                        ThresholdExpansioner(100, mode='invariants'))\n", "block_2.fit(even_1, odd_1, even_0_t, odd_0_t)\n", "_, _, even_invariants = block_2.transform(even_1, odd_1, even_0_t, odd_0_t)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["At his moment we have all parts of this standard sequence fitted:\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["True\n", "True\n", "True\n"]}], "source": ["nice = StandardSequence(initial_pca=initial_pca, blocks=[block_1, block_2])\n", "print(initial_pca.is_fitted())\n", "print(block_1.is_fitted())\n", "print(block_2.is_fitted())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["what about full model?"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["False\n"]}], "source": ["print(nice.is_fitted())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nope. \n", "\n", "At this point, there is a very high probability of making a mistake. Particularly one can feed StandardSequence with some fitted initial_pca along with blocks, which were fitted based not on the same initial_pca, with different initial_normalizer, or even on different data. In order to prevent it, there is a requirement to pass an additional flag guaranteed_parts_fitted_consistently = True to the model:"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["True\n"]}], "source": ["nice = StandardSequence(initial_pca=initial_pca,\n", "                        blocks=[block_1, block_2],\n", "                        guaranteed_parts_fitted_consistently=True)\n", "print(nice.is_fitted())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Model is considered to be fitted if 1) all parts are fitted and 2) if guaranteed_parts_fitted_consistently is set to be True\n", "\n", "**Golden rule:** Every time you pass guaranteed_parts_fitted_consistently = True make a pause and think twice. \n", "\n", "Let's check consistency:"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0.0\n"]}], "source": ["even_invariants_2 = nice.transform(coefficients,\n", "                                   return_only_invariants=True)[3]\n", "print(np.sum(np.abs(even_invariants - even_invariants_2)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This also works in other direction:"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["False\n", "False\n", "False\n", "True\n", "True\n", "True\n"]}], "source": ["initial_pca = IndividualLambdaPCAsBoth()\n", "block_1 = StandardBlock(ThresholdExpansioner(100), None,\n", "                        IndividualLambdaPCAsBoth(20))\n", "block_2 = StandardBlock(None, None, None,\n", "                        ThresholdExpansioner(100, mode='invariants'))\n", "\n", "print(initial_pca.is_fitted())\n", "print(block_1.is_fitted())\n", "print(block_2.is_fitted())\n", "\n", "nice = StandardSequence(initial_pca=initial_pca, blocks=[block_1, block_2])\n", "nice.fit(coefficients)\n", "\n", "print(initial_pca.is_fitted())\n", "print(block_1.is_fitted())\n", "print(block_2.is_fitted())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["StandardBlock behaves the same way:\n", "    "]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["False\n", "False\n", "True\n", "True\n"]}], "source": ["expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n", "print(expansioner.is_fitted())\n", "print(pca.is_fitted())\n", "\n", "block = StandardBlock(expansioner, None, pca)\n", "block.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n", "\n", "print(expansioner.is_fitted())\n", "print(pca.is_fitted())"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["True\n"]}], "source": ["expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n", "expansioner.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n", "even_1, odd_1 = expansioner.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n", "pca.fit(even_1, odd_1)\n", "\n", "block = StandardBlock(expansioner,\n", "                      None,\n", "                      pca,\n", "                      guaranteed_parts_fitted_consistently=True)\n", "\n", "print(block.is_fitted())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There is another group of blocks that accepts classes, such as sklearn.linear_model.Ridge in the initialization. But in their case, there is a need to apply several distinct regressors separately for each lambda channel and parity. Thus, the input regressor is cloned, and initial instances are not touched in any way. So, the material of this tutorial does not apply to purifiers. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 4}