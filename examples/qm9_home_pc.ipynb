{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ase\n",
    "from ase import Atoms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import ase.io\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTIES_NAMES = [\n",
    "    'tag', 'index', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2',\n",
    "    'zpve', 'U0', 'U', 'H', 'G', 'Cv'\n",
    "]\n",
    "\n",
    "\n",
    "def string_to_float(element):\n",
    "    '''because shit like 2.1997*^-6 happens'''\n",
    "    return float(element.replace('*^', 'e'))\n",
    "\n",
    "\n",
    "PROPERTIES_HANDLERS = [str, int\n",
    "                       ] + [string_to_float] * (len(PROPERTIES_NAMES) - 2)\n",
    "\n",
    "\n",
    "def parse_qm9_xyz(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = list(f)\n",
    "    #print(lines)\n",
    "    n_atoms = int(lines[0])\n",
    "    properties = {\n",
    "        name: handler(value)\n",
    "        for handler, name, value in zip(PROPERTIES_HANDLERS, PROPERTIES_NAMES,\n",
    "                                        lines[1].strip().split())\n",
    "    }\n",
    "    composition = \"\"\n",
    "    positions = []\n",
    "    for i in range(2, 2 + n_atoms):\n",
    "        composition += lines[i].strip().split()[0]\n",
    "        positions.append([\n",
    "            string_to_float(value) for value in lines[i].strip().split()[1:4]\n",
    "        ])\n",
    "\n",
    "    positions = np.array(positions)\n",
    "    result = Atoms(composition, positions=np.array(positions))\n",
    "    result.info.update(properties)\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_index(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = list(f)\n",
    "    proper_lines = lines[9:-1]\n",
    "    result = [int(line.strip().split()[0]) for line in proper_lines]\n",
    "    return np.array(result, dtype=int)\n",
    "\n",
    "\n",
    "def download_qm9(clean=True):\n",
    "    #downloading from https://figshare.com/collections/Quantum_chemistry_structures_and_properties_of_134_kilo_molecules/978904\n",
    "    os.system(\n",
    "        \"wget https://ndownloader.figshare.com/files/3195389 -O qm9_main.xyz.tar.bz2\"\n",
    "    )\n",
    "    os.system(\n",
    "        \"wget https://ndownloader.figshare.com/files/3195404 -O problematic_index.txt\"\n",
    "    )\n",
    "    os.system(\"mkdir qm9_main_structures\")\n",
    "    os.system(\"tar xjf qm9_main.xyz.tar.bz2 -C qm9_main_structures\")\n",
    "\n",
    "    names = [\n",
    "        name for name in os.listdir('qm9_main_structures/')\n",
    "        if name.endswith('.xyz')\n",
    "    ]\n",
    "    names = sorted(names)\n",
    "\n",
    "    structures = [\n",
    "        parse_qm9_xyz('qm9_main_structures/{}'.format(name))\n",
    "        for name in tqdm.tqdm(names)\n",
    "    ]\n",
    "\n",
    "    problematic_index = parse_index('problematic_index.txt')\n",
    "    np.save('problematic_index.npy', problematic_index)\n",
    "    ase.io.write('qm9_main.extxyz', structures)\n",
    "    if (clean):\n",
    "        os.system(\"rm -r qm9_main_structures\")\n",
    "        os.system(\"rm problematic_index.txt\")\n",
    "        os.system(\"rm qm9_main.xyz.tar.bz2\")\n",
    "    return structures, problematic_index\n",
    "\n",
    "\n",
    "def get_qm9(clean=True):\n",
    "    if ('qm9_main.extxyz' in os.listdir('.')) and \\\n",
    "              ('problematic_index.npy' in os.listdir('.')):\n",
    "        structures = ase.io.read('qm9_main.extxyz', index=':')\n",
    "        problematic_index = np.load('problematic_index.npy')\n",
    "        return structures, problematic_index\n",
    "    else:\n",
    "        return download_qm9(clean=clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, problematic_index = get_qm9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARTREE_TO_EV = 27.211386245988\n",
    "USE_PROBLEMATIC_INDEX = False\n",
    "np.random.seed(0)\n",
    "\n",
    "if (not USE_PROBLEMATIC_INDEX):\n",
    "    structures = [\n",
    "        structure for structure in structures\n",
    "        if structure.info['index'] not in problematic_index\n",
    "    ]\n",
    "\n",
    "del problematic_index  #it borrows indexing from 1 from qm9, deleting it away from sin\n",
    "\n",
    "permutation = np.random.permutation(len(structures))\n",
    "train_indices = permutation[0:2000]\n",
    "test_indices = permutation[2000:2500]\n",
    "environments_for_fitting = 1000  #number of environments to fit nice transfomers\n",
    "grid = [150, 200, 350, 500, 750, 1000, 1500, 2000]  #for learning curve\n",
    "\n",
    "#HYPERS for librascal spherical expansion coefficients\n",
    "HYPERS = {\n",
    "    'interaction_cutoff': 5,\n",
    "    'max_radial': 15,\n",
    "    'max_angular': 5,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.05,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model:\n",
    "def get_nice():\n",
    "    return StandardSequence([\n",
    "        StandardBlock(ThresholdExpansioner(num_expand=300),\n",
    "                      CovariantsPurifierBoth(max_take=10),\n",
    "                      IndividualLambdaPCAsBoth(n_components=100),\n",
    "                      ThresholdExpansioner(num_expand=1000, mode='invariants'),\n",
    "                      InvariantsPurifier(max_take=10),\n",
    "                      InvariantsPCA(n_components=200)),\n",
    "        StandardBlock(ThresholdExpansioner(num_expand=300),\n",
    "                      CovariantsPurifierBoth(max_take=10),\n",
    "                      IndividualLambdaPCAsBoth(n_components=100),\n",
    "                      ThresholdExpansioner(num_expand=1000, mode='invariants'),\n",
    "                      InvariantsPurifier(max_take=10),\n",
    "                      InvariantsPCA(n_components=200)),\n",
    "        StandardBlock(None, None, None,\n",
    "                      ThresholdExpansioner(num_expand=1000, mode='invariants'),\n",
    "                      InvariantsPurifier(max_take=10),\n",
    "                      InvariantsPCA(n_components=100))\n",
    "    ],\n",
    "                            initial_scaler=InitialScaler(\n",
    "                                mode='signal integral', individually=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structures = [structures[i] for i in train_indices]\n",
    "test_structures = [structures[i] for i in test_indices]\n",
    "\n",
    "all_species = get_all_species(train_structures + test_structures)\n",
    "\n",
    "train_coefficients = get_spherical_expansion(train_structures, HYPERS,\n",
    "                                             all_species)\n",
    "test_coefficients = get_spherical_expansion(test_structures, HYPERS,\n",
    "                                            all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coefficients = [\n",
    "    train_coefficients[key] for key in train_coefficients.keys()\n",
    "]\n",
    "all_coefficients = np.concatenate(all_coefficients, axis=0)\n",
    "np.random.shuffle(all_coefficients)\n",
    "all_coefficients = all_coefficients[0:environments_for_fitting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_single = get_nice()\n",
    "nice_single.fit(all_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using same nice transformer regardless of central specie\n",
    "nice = {specie: nice_single for specie in all_species}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = transform_sequentially(nice, train_structures, HYPERS,\n",
    "                                        all_species)\n",
    "test_features = transform_sequentially(nice, test_structures, HYPERS,\n",
    "                                       all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_features = get_compositional_features(train_structures, all_species)\n",
    "test_c_features = get_compositional_features(test_structures, all_species)\n",
    "\n",
    "train_features = np.concatenate([train_features, train_c_features], axis=1)\n",
    "test_features = np.concatenate([test_features, test_c_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_energies = [structure.info['U0'] for structure in train_structures]\n",
    "train_energies = np.array(train_energies) * HARTREE_TO_EV\n",
    "\n",
    "test_energies = [structure.info['U0'] for structure in test_structures]\n",
    "test_energies = np.array(test_energies) * HARTREE_TO_EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(first, second):\n",
    "    return np.sqrt(np.mean((first - second)**2))\n",
    "\n",
    "\n",
    "def get_mae(first, second):\n",
    "    return np.mean(np.abs(first - second))\n",
    "\n",
    "\n",
    "def estimate_performance(regressor, data_train, data_test, targets_train,\n",
    "                         targets_test):\n",
    "    regressor.fit(data_train, targets_train)\n",
    "    predictions = regressor.predict(data_test)\n",
    "    return get_rmse(predictions,\n",
    "                    targets_test), get_mae(predictions, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_compositional = []\n",
    "for el in tqdm.tqdm(grid):\n",
    "    errors_compositional.append(\n",
    "        estimate_performance(BayesianRidge(), train_c_features[:el],\n",
    "                             test_c_features, train_energies[:el],\n",
    "                             test_energies))\n",
    "\n",
    "errors_compositional = np.array(errors_compositional)\n",
    "errors_nice = []\n",
    "for el in tqdm.tqdm(grid):\n",
    "    # because without this step with residuals\n",
    "    # joint fitting might face problems due to\n",
    "    # regularization\n",
    "    regressor = BayesianRidge()\n",
    "    regressor.fit(train_c_features[:el], train_energies[:el])\n",
    "\n",
    "    residuals_train = train_energies[:el] - regressor.predict(\n",
    "        train_c_features[:el])\n",
    "    residuals_test = test_energies - regressor.predict(test_c_features)\n",
    "\n",
    "    errors_nice.append(\n",
    "        estimate_performance(BayesianRidge(), train_features[:el],\n",
    "                             test_features, residuals_train, residuals_test))\n",
    "\n",
    "errors_nice = np.array(errors_nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "axes[0].plot(grid, errors_compositional[:, 0], 'ro')\n",
    "axes[0].plot(grid, errors_compositional[:, 0], 'r', label='only compositional')\n",
    "\n",
    "axes[0].plot(grid, errors_nice[:, 0], 'bo')\n",
    "axes[0].plot(grid, errors_nice[:, 0], 'b', label='nice')\n",
    "\n",
    "axes[0].set_xlabel(\"n_train\")\n",
    "axes[0].set_ylabel(\"rmse, eV\")\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(grid, errors_compositional[:, 1], 'ro')\n",
    "axes[1].plot(grid, errors_compositional[:, 1], 'r', label='only compositional')\n",
    "\n",
    "axes[1].plot(grid, errors_nice[:, 1], 'bo')\n",
    "axes[1].plot(grid, errors_nice[:, 1], 'b', label='nice')\n",
    "\n",
    "axes[1].set_xlabel(\"n_train\")\n",
    "axes[1].set_ylabel(\"mae, eV\")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "plt.legend(loc='upper center')\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mae: {} eV\".format(errors_nice[-1][0]))\n",
    "print(\"rmse: {} eV\".format(errors_nice[-1][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
