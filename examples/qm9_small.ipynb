{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ase\n",
    "from ase import Atoms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import ase.io\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTIES_NAMES = ['tag', 'index', 'A', 'B', 'C', 'mu',\n",
    "                    'alpha', 'homo', 'lumo', 'gap', 'r2',\n",
    "                    'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "\n",
    "\n",
    "def string_to_float(element):\n",
    "    '''because shit like 2.1997*^-6 happens'''\n",
    "    return float(element.replace('*^', 'e'))\n",
    "\n",
    "PROPERTIES_HANDLERS = [str, int] + [string_to_float] * (len(PROPERTIES_NAMES) - 2)\n",
    "\n",
    "def parse_qm9_xyz(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = list(f)\n",
    "    #print(lines)\n",
    "    n_atoms = int(lines[0])\n",
    "    properties = {name:handler(value)\n",
    "                  for handler, name, value in zip(PROPERTIES_HANDLERS,\n",
    "                                            PROPERTIES_NAMES,\n",
    "                                            lines[1].strip().split())}\n",
    "    composition = \"\"\n",
    "    positions = []\n",
    "    for i in range(2, 2 + n_atoms):\n",
    "        composition += lines[i].strip().split()[0]\n",
    "        positions.append([string_to_float(value) \n",
    "                          for value in lines[i].strip().split()[1:4]])\n",
    "        \n",
    "    \n",
    "    positions = np.array(positions)\n",
    "    result = Atoms(composition, positions = np.array(positions))\n",
    "    result.info.update(properties)\n",
    "    return result\n",
    "\n",
    "def parse_index(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = list(f)\n",
    "    proper_lines = lines[9:-1]\n",
    "    result = [int(line.strip().split()[0]) for line in proper_lines]\n",
    "    return np.array(result, dtype = int)\n",
    "\n",
    "def download_qm9(clean = True):\n",
    "    #downloading from https://figshare.com/collections/Quantum_chemistry_structures_and_properties_of_134_kilo_molecules/978904\n",
    "    os.system(\"wget https://ndownloader.figshare.com/files/3195389 -O qm9_main.xyz.tar.bz2\")\n",
    "    os.system(\"wget https://ndownloader.figshare.com/files/3195404 -O problematic_index.txt\")\n",
    "    os.system(\"mkdir qm9_main_structures\")\n",
    "    os.system(\"tar xjf qm9_main.xyz.tar.bz2 -C qm9_main_structures\")\n",
    "    \n",
    "    names = [name for name in os.listdir('qm9_main_structures/') if name.endswith('.xyz')]\n",
    "    names = sorted(names)\n",
    "    \n",
    "    structures = [parse_qm9_xyz('qm9_main_structures/{}'.format(name))\n",
    "              for name in tqdm.tqdm(names)]\n",
    "    \n",
    "    problematic_index = parse_index('problematic_index.txt')\n",
    "    np.save('problematic_index.npy', problematic_index)\n",
    "    ase.io.write('qm9_main.extxyz', structures)\n",
    "    if (clean):\n",
    "        os.system(\"rm -r qm9_main_structures\")\n",
    "        os.system(\"rm problematic_index.txt\")\n",
    "        os.system(\"rm qm9_main.xyz.tar.bz2\")\n",
    "    return structures, problematic_index\n",
    "              \n",
    "def get_qm9(clean = True):\n",
    "    if ('qm9_main.extxyz' in os.listdir('.')) and \\\n",
    "              ('problematic_index.npy' in os.listdir('.')):\n",
    "        structures = ase.io.read('qm9_main.extxyz', index = ':')\n",
    "        problematic_index = np.load('problematic_index.npy')\n",
    "        return structures, problematic_index\n",
    "    else:\n",
    "        return download_qm9(clean = clean)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, problematic_index = get_qm9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARTREE_TO_EV = 27.211386245988\n",
    "USE_PROBLEMATIC_INDEX = False\n",
    "np.random.seed(0)\n",
    "\n",
    "if (not USE_PROBLEMATIC_INDEX):\n",
    "    structures = [structure for structure in structures\n",
    "                if structure.info['index'] not in problematic_index]\n",
    "    \n",
    "del problematic_index #it borrows indexing from 1 from qm9, deleting it away from sin\n",
    " \n",
    "permutation = np.random.permutation(len(structures))\n",
    "print(len(structures))\n",
    "train_indices = permutation[0:100000]  \n",
    "test_indices = permutation[100000:]     \n",
    "environments_for_fitting = 5000    #number of environments to fit nice transfomers\n",
    "grid =  [150, 200, 350, 500, 750, 1000,\n",
    "         1500, 2000, 3500, 5000, 7500, 10000,\n",
    "         15000, 20000, 35000, 50000, 75000, 100000] #for learning curve\n",
    "\n",
    "#HYPERS for librascal spherical expansion coefficients\n",
    "HYPERS = {'interaction_cutoff': 5.0,\n",
    "          'max_radial': 5, \n",
    "          'max_angular': 5, \n",
    "          'gaussian_sigma_constant': 0.3,\n",
    "          'gaussian_sigma_type': 'Constant',\n",
    "          'cutoff_smooth_width': 0.5, \n",
    "          'radial_basis': 'GTO', \n",
    "          'cutoff_function_type': 'RadialScaling',\n",
    "          'cutoff_function_parameters': \n",
    "          {'rate': 2, 'scale': 1, 'exponent': 6, 'interaction_cutoff': 5.0, 'cutoff_smooth_width': 0.5}, \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model:\n",
    "def get_transformer():\n",
    "    return StandardSequence([StandardBlock(ThresholdExpansioner(num_expand = 5000),\n",
    "                                              CovariantsPurifierBoth(max_take = 100),\n",
    "                                                  IndividualLambdaPCAsBoth(2000),\n",
    "                                                  ThresholdExpansioner(num_expand = 50000, mode = 'invariants'),\n",
    "                                              InvariantsPurifier(max_take = 100),\n",
    "                                                 InvariantsPCA(n_components = 1500)),                            \n",
    "                             StandardBlock(None,\n",
    "                                           None,\n",
    "                                           None,\n",
    "                                                  ThresholdExpansioner(num_expand = 50000, mode = 'invariants'),\n",
    "                                              InvariantsPurifier(max_take = 100),\n",
    "                                                 InvariantsPCA(n_components = 1500))\n",
    "                            ],\n",
    "                            initial_scaler = InitialScaler(mode = 'signal integral',\n",
    "                                                           individually = True)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structures = [structures[i] for i in train_indices]\n",
    "test_structures = [structures[i] for i in test_indices]\n",
    "\n",
    "all_species = get_all_species(train_structures + test_structures)\n",
    "\n",
    "train_coefficients = get_spherical_expansion(train_structures, HYPERS, all_species)\n",
    "test_coefficients = get_spherical_expansion(test_structures, HYPERS, all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coefficients = [train_coefficients[key] for key in train_coefficients.keys()]\n",
    "all_coefficients = np.concatenate(all_coefficients, axis = 0)\n",
    "np.random.shuffle(all_coefficients)\n",
    "all_coefficients = all_coefficients[0:environments_for_fitting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = get_transformer()\n",
    "transformer.fit(all_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using same transformer regardless of central specie\n",
    "transformers = {specie : transformer for specie in all_species}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = transform_sequentially(transformers, \n",
    "                                        train_structures, HYPERS, \n",
    "                                        all_species, block_size = 250)\n",
    "test_features = transform_sequentially(transformers,\n",
    "                                        test_structures, HYPERS, \n",
    "                                       all_species, block_size = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_features = get_compositional_features(train_structures, all_species)\n",
    "test_c_features = get_compositional_features(test_structures, all_species)\n",
    "\n",
    "train_features = np.concatenate([train_features, train_c_features], axis = 1)\n",
    "test_features = np.concatenate([test_features, test_c_features], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_energies = [structure.info['U0'] for structure in train_structures]\n",
    "train_energies = np.array(train_energies) * HARTREE_TO_EV\n",
    "\n",
    "test_energies = [structure.info['U0'] for structure in test_structures]\n",
    "test_energies = np.array(test_energies) * HARTREE_TO_EV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(first, second):\n",
    "    return np.sqrt(np.mean((first - second) ** 2))\n",
    "def get_mae(first, second):\n",
    "    return np.mean(np.abs(first - second))\n",
    "\n",
    "def estimate_performance(clf, data_train, data_test, targets_train, targets_test):\n",
    "    clf.fit(data_train, targets_train)\n",
    "    predictions = clf.predict(data_test)\n",
    "    return get_rmse(predictions, targets_test), get_mae(predictions, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def get_performance(alpha):\n",
    "    \n",
    "    errors_compositional = []\n",
    "    for el in tqdm.tqdm(grid):   \n",
    "        errors_compositional.append(estimate_performance(Ridge(alpha = alpha), train_c_features[:el],\n",
    "                                           test_c_features, train_energies[:el],\n",
    "                                           test_energies))\n",
    "\n",
    "    errors_compositional = np.array(errors_compositional)\n",
    "    errors_nice = []\n",
    "    for el in tqdm.tqdm(grid):\n",
    "        # because without this step with residuals\n",
    "        # joint fitting might face problems due to\n",
    "        # regularization\n",
    "        clf = Ridge(alpha = alpha)\n",
    "        clf.fit(train_c_features[:el], train_energies[:el])\n",
    "\n",
    "        residuals_train = train_energies[:el] - clf.predict(train_c_features[:el])\n",
    "        residuals_test = test_energies - clf.predict(test_c_features)\n",
    "\n",
    "        errors_nice.append(estimate_performance(Ridge(alpha = alpha), train_features[:el],\n",
    "                                           test_features, residuals_train,\n",
    "                                           residuals_test))\n",
    "\n",
    "    errors_nice = np.array(errors_nice)\n",
    "    \n",
    "    print(\"alpha: \", alpha)\n",
    "    print(\"rmse: \", errors_nice[-1][0], \" eV\")\n",
    "    print(\"mae: \", errors_nice[-1][1], \" eV\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "    axes[0].plot(grid, errors_compositional[:, 0], 'ro')\n",
    "    axes[0].plot(grid, errors_compositional[:, 0], 'r', label = 'only compositional')\n",
    "\n",
    "    axes[0].plot(grid, errors_nice[:, 0], 'bo')\n",
    "    axes[0].plot(grid, errors_nice[:, 0], 'b', label = 'nice')\n",
    "\n",
    "    axes[0].set_xlabel(\"n_train\")\n",
    "    axes[0].set_ylabel(\"rmse, eV\")\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_yscale('log')\n",
    "\n",
    "    axes[1].plot(grid, errors_compositional[:, 1], 'ro')\n",
    "    axes[1].plot(grid, errors_compositional[:, 1], 'r', label = 'only compositional')\n",
    "\n",
    "    axes[1].plot(grid, errors_nice[:, 1], 'bo')\n",
    "    axes[1].plot(grid, errors_nice[:, 1], 'b', label = 'nice')\n",
    "\n",
    "    axes[1].set_xlabel(\"n_train\")\n",
    "    axes[1].set_ylabel(\"mae, eV\")\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_yscale('log')\n",
    "    plt.legend(loc = 'upper center')\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance(1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
