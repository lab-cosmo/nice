{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading dataset from https://archive.materialscloud.org/record/2020.110\n",
    "\n",
    "!wget \"https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\" -O methane.extxyz.gz\n",
    "!gunzip -k methane.extxyz.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ase.io\n",
    "import tqdm\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HARTREE_TO_EV = 27.211386245988\n",
    "train_subset = \"0:100000\"    #input for ase.io.read command\n",
    "test_subset = \"3050000:3130000\"     #input to ase.io.read command\n",
    "environments_for_fitting = 5000    #number of environments to fit nice transfomers\n",
    "grid =   [150, 200, 350, 500, 750, 1000, 1500, 2000, 3000,\n",
    "          5000, 7500, 10000, 15000, 20000,\n",
    "          30000, 50000, 75000, 100000] #for learning curve\n",
    "\n",
    "#HYPERS for librascal spherical expansion coefficients\n",
    "HYPERS = {\n",
    "'interaction_cutoff': 6.3,\n",
    "'max_radial': 5,\n",
    "'max_angular': 5,\n",
    "'gaussian_sigma_type': 'Constant',\n",
    "'gaussian_sigma_constant': 0.05,\n",
    "'cutoff_smooth_width': 0.3,\n",
    "'radial_basis': 'GTO'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model:\n",
    "def get_transformer():\n",
    "    return StandardSequence([StandardBlock(ThresholdExpansioner(num_expand = 1000),\n",
    "                                              CovariantsPurifierBoth(max_take = 100),\n",
    "                                                  IndividualLambdaPCAsBoth(500),\n",
    "                                                 None,\n",
    "                                                 None,\n",
    "                                                  None),\n",
    "                            StandardBlock(ThresholdExpansioner(num_expand = 3000),\n",
    "                                              CovariantsPurifierBoth(max_take = 100),\n",
    "                                                  IndividualLambdaPCAsBoth(500),\n",
    "                                                  ThresholdExpansioner(num_expand = 5000, mode = 'invariants'),\n",
    "                                              InvariantsPurifier(max_take = 100),\n",
    "                                                 InvariantsPCA(n_components = 1000)),\n",
    "                             StandardBlock(None,\n",
    "                                             None,\n",
    "                                                  None,\n",
    "                                                  ThresholdExpansioner(num_expand = 5000, mode = 'invariants'),\n",
    "                                              InvariantsPurifier(max_take = 100),\n",
    "                                                  InvariantsPCA(n_components = 2000))\n",
    "                                   ],\n",
    "                            initial_scaler = InitialScaler(mode = 'signal integral',\n",
    "                                                           individually = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structures = ase.io.read('methane.extxyz', \n",
    "                         index = train_subset)\n",
    "\n",
    "test_structures = ase.io.read('methane.extxyz', \n",
    "                         index = test_subset)\n",
    "\n",
    "all_species = get_all_species(train_structures + test_structures)\n",
    "\n",
    "train_coefficients = get_spherical_expansion(train_structures, HYPERS, all_species)\n",
    "\n",
    "\n",
    "\n",
    "test_coefficients = get_spherical_expansion(test_structures, HYPERS, all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#individual transformers for each atomic specie in dataset\n",
    "transformers = {}\n",
    "for key in train_coefficients.keys():\n",
    "    transformers[key] = get_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_coefficients.keys():\n",
    "    transformers[key].fit(train_coefficients[key][:environments_for_fitting])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = transform_sequentially(transformers, \n",
    "                                        train_structures, HYPERS, all_species)\n",
    "test_features = transform_sequentially(transformers,\n",
    "                                        test_structures, HYPERS, all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_energies = [structure.info['energy'] for structure in train_structures]\n",
    "train_energies = np.array(train_energies) * HARTREE_TO_EV\n",
    "\n",
    "test_energies = [structure.info['energy'] for structure in test_structures]\n",
    "test_energies = np.array(test_energies) * HARTREE_TO_EV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(first, second):\n",
    "    return np.sqrt(np.mean((first - second) ** 2))\n",
    "\n",
    "def get_standard_deviation(values):\n",
    "    return np.sqrt(np.mean((values - np.mean(values)) ** 2))\n",
    "\n",
    "def get_relative_performance(predictions, values):\n",
    "    return get_rmse(predictions, values) / get_standard_deviation(values)\n",
    "\n",
    "def estimate_performance(clf, data_train, data_test, targets_train, targets_test):\n",
    "    clf.fit(data_train, targets_train)\n",
    "    return get_relative_performance(clf.predict(data_test), targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for el in tqdm.tqdm(grid):   \n",
    "    errors.append(estimate_performance(BayesianRidge(), train_features[:el],\n",
    "                                       test_features, train_energies[:el],\n",
    "                                       test_energies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(grid, errors, 'bo')\n",
    "plt.plot(grid, errors, 'b')\n",
    "plt.xlabel(\"number of structures\")\n",
    "plt.ylabel(\"relative error\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
