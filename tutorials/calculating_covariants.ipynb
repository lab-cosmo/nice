{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating covariants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorial we calculated invariant representation of atomic environment and used to for prediction of energies - invariant properties. \n",
    "\n",
    "In case when there is need to predict covariant properties covariants instead of invariants are required. This tutorial shows how to calculate them.\n",
    "\n",
    "First of all we need to get fitted instance of model as in the previous tutorial. It is done by the following preliminaries cell: (with the only difference that since we want to calculate covariants, we clearly shouldn't left covariants branch of the last block empty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-12 00:41:24--  https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\n",
      "Resolving archive.materialscloud.org (archive.materialscloud.org)... 148.187.96.41\n",
      "Connecting to archive.materialscloud.org (archive.materialscloud.org)|148.187.96.41|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://object.cscs.ch/archive/b6/12/d8e3-58af-4374-96ba-b3551ac5d2f4/data?response-content-type=application%2Foctet-stream&response-content-disposition=attachment%3B%20filename%3Dmethane.extxyz.gz&Expires=1602456144&Signature=xBvXs4RBa6ynAsKMKhFA0%2FfRVYA%3D&AWSAccessKeyId=ee64314446074ed3ab5f375a522a4893 [following]\n",
      "--2020-10-12 00:41:24--  https://object.cscs.ch/archive/b6/12/d8e3-58af-4374-96ba-b3551ac5d2f4/data?response-content-type=application%2Foctet-stream&response-content-disposition=attachment%3B%20filename%3Dmethane.extxyz.gz&Expires=1602456144&Signature=xBvXs4RBa6ynAsKMKhFA0%2FfRVYA%3D&AWSAccessKeyId=ee64314446074ed3ab5f375a522a4893\n",
      "Resolving object.cscs.ch (object.cscs.ch)... 148.187.25.200, 148.187.25.202, 148.187.25.201\n",
      "Connecting to object.cscs.ch (object.cscs.ch)|148.187.25.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1218139661 (1.1G) [application/octet-stream]\n",
      "Saving to: ‘methane.extxyz.gz’\n",
      "\n",
      "methane.extxyz.gz   100%[===================>]   1.13G  30.7MB/s    in 28s     \n",
      "\n",
      "2020-10-12 00:41:53 (40.9 MB/s) - ‘methane.extxyz.gz’ saved [1218139661/1218139661]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 49.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 37.77it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 48.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.51it/s]\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n",
      "/home/pozdn/.local/lib/python3.6/site-packages/nice/blocks/compressors.py:201: UserWarning: Amount of provided data is less than the desired one to fit PCA. Number of components is 200, desired number of environments is 2000, actual number of environments is 1000.\n",
      "  self.n_components, num_fit_now, X.shape[0]))\n"
     ]
    }
   ],
   "source": [
    "# cell to wrap in collapsible in future\n",
    "\n",
    "# downloading dataset from https://archive.materialscloud.org/record/2020.110\n",
    "\n",
    "!wget \"https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\" -O methane.extxyz.gz\n",
    "!gunzip -k methane.extxyz.gz\n",
    "\n",
    "import numpy as np\n",
    "import ase.io\n",
    "import tqdm\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "HARTREE_TO_EV = 27.211386245988\n",
    "train_subset = \"0:10000\"    #input for ase.io.read command\n",
    "test_subset = \"10000:15000\"     #input to ase.io.read command\n",
    "environments_for_fitting = 1000    #number of environments to fit nice transfomers\n",
    "grid =  [150, 200, 350, 500, 750, 1000,\n",
    "         1500, 2000, 3000, 5000, 7500, 10000] #for learning curve\n",
    "\n",
    "#HYPERS for librascal spherical expansion coefficients\n",
    "HYPERS = {\n",
    "'interaction_cutoff': 6.3,\n",
    "'max_radial': 5,\n",
    "'max_angular': 5,\n",
    "'gaussian_sigma_type': 'Constant',\n",
    "'gaussian_sigma_constant': 0.05,\n",
    "'cutoff_smooth_width': 0.3,\n",
    "'radial_basis': 'GTO'\n",
    "}\n",
    "\n",
    "#our model:\n",
    "def get_transformer():\n",
    "    return StandardSequence([StandardBlock(ThresholdExpansioner(num_expand = 150),\n",
    "                                              CovariantsPurifierBoth(max_take = 10),\n",
    "                                                  IndividualLambdaPCAsBoth(n_components = 50),\n",
    "                                                 ThresholdExpansioner(num_expand =300, mode = 'invariants'),\n",
    "                                                 InvariantsPurifier(max_take = 50),\n",
    "                                                  InvariantsPCA(n_components = 200)),\n",
    "                             StandardBlock(ThresholdExpansioner(num_expand = 150),\n",
    "                                              CovariantsPurifierBoth(max_take = 10),\n",
    "                                                  IndividualLambdaPCAsBoth(n_components = 10),\n",
    "                                                 ThresholdExpansioner(num_expand =300, mode = 'invariants'),\n",
    "                                                 InvariantsPurifier(max_take = 50),\n",
    "                                                  InvariantsPCA(n_components = 200)),\n",
    "                            StandardBlock(ThresholdExpansioner(num_expand = 150),\n",
    "                                              CovariantsPurifierBoth(max_take = 10),\n",
    "                                                  None,\n",
    "                                                  ThresholdExpansioner(num_expand =300, mode = 'invariants'),\n",
    "                                              InvariantsPurifier(max_take = 50),\n",
    "                                                 InvariantsPCA(n_components = 200))\n",
    "                                   ],\n",
    "                            initial_scaler = InitialScaler(mode = 'signal integral',\n",
    "                                                           individually = True)\n",
    "                          )\n",
    "\n",
    "\n",
    "train_structures = ase.io.read('methane.extxyz', \n",
    "                         index = train_subset)\n",
    "\n",
    "test_structures = ase.io.read('methane.extxyz', \n",
    "                         index = test_subset)\n",
    "\n",
    "all_species = get_all_species(train_structures + test_structures)\n",
    "\n",
    "train_coefficients = get_spherical_expansion(train_structures, HYPERS, all_species)\n",
    "\n",
    "\n",
    "\n",
    "test_coefficients = get_spherical_expansion(test_structures, HYPERS, all_species)\n",
    "\n",
    "#individual transformers for each atomic specie in dataset\n",
    "transformers = {}\n",
    "for key in train_coefficients.keys():\n",
    "    transformers[key] = get_transformer()\n",
    "    \n",
    "for key in train_coefficients.keys():\n",
    "    transformers[key].fit(train_coefficients[key][:environments_for_fitting])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to call .transform method with return_only_invariants = False, which is default value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_even, data_odd, invariants_even = transformers[1].transform(train_coefficients[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result is data_even, data_odd and invariants_even. First two objects are covariants, the last is invariants. \n",
    "\n",
    "There is one another important symmetry in addition to translational and rotational one. Usually atomic properties, such as energy, transform in certain way also with respect to inversion. Particularly, energy is invariant with respect to it. \n",
    "\n",
    "In NICE features are separated in two groups - the ones which are invariant with respect to inversion, and the ones which change their sign. The first are called even, second are called odd. \n",
    "\n",
    "Now let's take a look at the returned objects more closely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invariants is the same object as in the previous tutorial - dictionary, where keys are body order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10)\n",
      "(40000, 200)\n",
      "(40000, 200)\n",
      "(40000, 200)\n"
     ]
    }
   ],
   "source": [
    "for key in invariants_even.keys():\n",
    "    print(invariants_even[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returned covariants are covariants after last block, i. e. in our case of body order 4. \n",
    "(functionality to get all covariants of all body order from StandardSequence will be added in the next version of NICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even covariants are packed in the class Data, which has two relevant fields - \n",
    ".covariants_ and .actual_sizes_. (getters are also to be added in the next version) First is np.array with covariants themselves. It has following indexing -[environmental_index, feature_index, lambda, m]. But the problem is that for each lambda channel actual number of features is different. Thus, shape of this array doesn't reflect real number of meaningfull entries. Information about actual number of features is stored in .actual_sizes_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nice.nice_utilities.Data'>\n",
      "shape of even covariants array: (40000, 87, 6, 11)\n",
      "actual sizes of even covariants: [22 55 73 83 87 76]\n"
     ]
    }
   ],
   "source": [
    "print(type(data_even))\n",
    "print(\"shape of even covariants array: {}\".format(data_even.covariants_.shape))\n",
    "print(\"actual sizes of even covariants: {}\".format(data_even.actual_sizes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for odd covariants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of odd covariants array: (40000, 88, 6, 11)\n",
      "actual sizes of odd covariants: [20 54 72 87 88 75]\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of odd covariants array: {}\".format(data_odd.covariants_.shape))\n",
    "print(\"actual sizes of odd covariants: {}\".format(data_odd.actual_sizes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one another point - that for each lambda channel size of covariant vectors is (2 * lambda + 1). These vectors are stored from the beginning. It means that meaningfull entries for each lambda are located in [:, :, lambda, :(2 * lambda + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [nice article](https://aip.scitation.org/doi/10.1063/5.0021116) other definition of parity is used. Covariants are splitted into true and pseudo groups. All covariants in true group are transformed with respect to inversion as (-1)^lambda, while all covariants in the pseudo group are transformed as (-1) ^ (lambda + 1). \n",
    "\n",
    "There is special class - ParityDefinitionChanger to switch between these definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 87, 6, 11)\n",
      "[22 54 73 87 87 75]\n",
      "(40000, 88, 6, 11)\n",
      "[20 55 72 83 88 76]\n"
     ]
    }
   ],
   "source": [
    "data_true, data_pseudo = ParityDefinitionChanger().transform(data_even, data_odd)\n",
    "\n",
    "print(data_true.covariants_.shape)\n",
    "print(data_true.actual_sizes_)\n",
    "\n",
    "print(data_pseudo.covariants_.shape)\n",
    "print(data_pseudo.actual_sizes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation is symmetric, thus, we can use this it once again to go back from true and pseudo covariants to even and odd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_even, data_odd = ParityDefinitionChanger().transform(data_true, data_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one another discrepancy - covariants defined in the nice article, are smaller by the factor of (2 * lambda + 1). Thus, the last step to get full compliance is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in range(6):\n",
    "    data_true.covariants_[:, :data_true.actual_sizes_[lambd],\n",
    "                          lambd, :(2 * lambd + 1)] /= (2 * lambd + 1)\n",
    "    data_pseudo.covariants_[:, :data_pseudo.actual_sizes_[lambd],\n",
    "                            lambd, :(2 * lambd + 1)] /= (2 * lambd + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
