{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not always clear how to select good hyperparameters for calculations. The second tutorial \"Getting insights about the model, \" showed how to plot PCA spectrums for all lambda channels and parities. This information, along with the other one, such as regression accuracy, might be useful to select better hypers. Particularly, the most straightforward way is to select the number of PCA components in such a way as to cover the most part of the variance and do it successively from block to block. \n",
    "\n",
    "In this case, it is very undesirable to fit all parts of the model, including not changed ones from scratch. One possible way around is to do all things by hand, as was described in the tutorial \"Constructor or non standard_sequence,\" but there would be an additional headache with packing resulting blocks into a single model with a convenient .transform method. Nice toolbox has the capability to do it very succinctly.\n",
    "\n",
    "First of all, we need to get spherical expansion coefficients the same way as in previous tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-04 12:38:33--  https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\n",
      "Resolving archive.materialscloud.org (archive.materialscloud.org)... 148.187.149.49\n",
      "Connecting to archive.materialscloud.org (archive.materialscloud.org)|148.187.149.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://object.cscs.ch/archive/b6/12/d8e3-58af-4374-96ba-b3551ac5d2f4/data?response-content-type=application%2Foctet-stream&response-content-disposition=attachment%3B%20filename%3Dmethane.extxyz.gz&Signature=m5bCM21hSbBLcX0R6CrPB8BzOMg%3D&AWSAccessKeyId=f30fe0bddb114e91abe6adf3d36c6f2e&Expires=1667561973 [following]\n",
      "--2022-11-04 12:38:33--  https://object.cscs.ch/archive/b6/12/d8e3-58af-4374-96ba-b3551ac5d2f4/data?response-content-type=application%2Foctet-stream&response-content-disposition=attachment%3B%20filename%3Dmethane.extxyz.gz&Signature=m5bCM21hSbBLcX0R6CrPB8BzOMg%3D&AWSAccessKeyId=f30fe0bddb114e91abe6adf3d36c6f2e&Expires=1667561973\n",
      "Resolving object.cscs.ch (object.cscs.ch)... 148.187.25.201, 148.187.25.204, 148.187.25.200, ...\n",
      "Connecting to object.cscs.ch (object.cscs.ch)|148.187.25.201|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1218139661 (1.1G) [application/octet-stream]\n",
      "Saving to: ‘methane.extxyz.gz’\n",
      "\n",
      "methane.extxyz.gz   100%[===================>]   1.13G   169MB/s    in 6.9s    \n",
      "\n",
      "2022-11-04 12:38:40 (167 MB/s) - ‘methane.extxyz.gz’ saved [1218139661/1218139661]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 124.68it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 262.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# downloading dataset from https://archive.materialscloud.org/record/2020.110\n",
    "\n",
    "!wget \"https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\" -O methane.extxyz.gz\n",
    "!gunzip -k methane.extxyz.gz\n",
    "\n",
    "import numpy as np\n",
    "import ase.io\n",
    "import tqdm\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "structures = ase.io.read('methane.extxyz', index='0:1000')\n",
    "\n",
    "HYPERS = {\n",
    "    'interaction_cutoff': 6.3,\n",
    "    'max_radial': 5,\n",
    "    'max_angular': 5,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.05,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO'\n",
    "}\n",
    "\n",
    "all_species = get_all_species(structures)\n",
    "\n",
    "coefficients = get_spherical_expansion(structures, HYPERS, all_species)\n",
    "coefficients = coefficients[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coefficients are now spherical expansion coefficients for H centered environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 10, 6, 11)\n"
     ]
    }
   ],
   "source": [
    "print(coefficients.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the first steps from standar sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_0, odd_0 = InitialTransformer().transform(coefficients)\n",
    "initial_pca = IndividualLambdaPCAsBoth()\n",
    "initial_pca.fit(even_0, odd_0)\n",
    "even_0_t, odd_0_t = initial_pca.transform(even_0, odd_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit couple of standard blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_1 = StandardBlock(ThresholdExpansioner(100), None,\n",
    "                        IndividualLambdaPCAsBoth(20))\n",
    "block_1.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "even_1, odd_1, _ = block_1.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "\n",
    "block_2 = StandardBlock(None, None, None,\n",
    "                        ThresholdExpansioner(100, mode='invariants'))\n",
    "block_2.fit(even_1, odd_1, even_0_t, odd_0_t)\n",
    "_, _, even_invariants = block_2.transform(even_1, odd_1, even_0_t, odd_0_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At his moment we have all parts of this standard sequence fitted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nice = StandardSequence(initial_pca=initial_pca, blocks=[block_1, block_2])\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what about full model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(nice.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope. \n",
    "\n",
    "At this point, there is a very high probability of making a mistake. Particularly one can feed StandardSequence with some fitted initial_pca along with blocks, which were fitted based not on the same initial_pca, with different initial_normalizer, or even on different data. In order to prevent it, there is a requirement to pass an additional flag guaranteed_parts_fitted_consistently = True to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "nice = StandardSequence(initial_pca=initial_pca,\n",
    "                        blocks=[block_1, block_2],\n",
    "                        guaranteed_parts_fitted_consistently=True)\n",
    "print(nice.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is considered to be fitted if 1) all parts are fitted and 2) if guaranteed_parts_fitted_consistently is set to be True\n",
    "\n",
    "**Golden rule:** Every time you pass guaranteed_parts_fitted_consistently = True make a pause and think twice. \n",
    "\n",
    "Let's check consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "even_invariants_2 = nice.transform(coefficients,\n",
    "                                   return_only_invariants=True)[3]\n",
    "print(np.sum(np.abs(even_invariants - even_invariants_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works in other direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "initial_pca = IndividualLambdaPCAsBoth()\n",
    "block_1 = StandardBlock(ThresholdExpansioner(100), None,\n",
    "                        IndividualLambdaPCAsBoth(20))\n",
    "block_2 = StandardBlock(None, None, None,\n",
    "                        ThresholdExpansioner(100, mode='invariants'))\n",
    "\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())\n",
    "\n",
    "nice = StandardSequence(initial_pca=initial_pca, blocks=[block_1, block_2])\n",
    "nice.fit(coefficients)\n",
    "\n",
    "print(initial_pca.is_fitted())\n",
    "print(block_1.is_fitted())\n",
    "print(block_2.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardBlock behaves the same way:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n",
    "print(expansioner.is_fitted())\n",
    "print(pca.is_fitted())\n",
    "\n",
    "block = StandardBlock(expansioner, None, pca)\n",
    "block.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "\n",
    "print(expansioner.is_fitted())\n",
    "print(pca.is_fitted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "expansioner, pca = ThresholdExpansioner(100), IndividualLambdaPCAsBoth(20)\n",
    "expansioner.fit(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "even_1, odd_1 = expansioner.transform(even_0_t, odd_0_t, even_0_t, odd_0_t)\n",
    "pca.fit(even_1, odd_1)\n",
    "\n",
    "block = StandardBlock(expansioner,\n",
    "                      None,\n",
    "                      pca,\n",
    "                      guaranteed_parts_fitted_consistently=True)\n",
    "\n",
    "print(block.is_fitted())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another group of blocks that accepts classes, such as sklearn.linear_model.Ridge in the initialization. But in their case, there is a need to apply several distinct regressors separately for each lambda channel and parity. Thus, the input regressor is cloned, and initial instances are not touched in any way. So, the material of this tutorial does not apply to purifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
