{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom regressors into purifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was already mentioned in the first tutorial, purifiers can accept arbitrarily linear regressors from sklearn.linear_model. In order to feed it with a custom linear regressor, some requirements should be fulfilled. Firstly, it should have the same interface as linear regressors from sklearn with the fit and predict methods. Secondly, it should fulfill sklearn requirements to make it possible to clone with [sklearn.base.clone](https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html) function. This tutorial shows an example of such a class. \n",
    "\n",
    "As before, let's calculate spherical expansion coefficients for H environments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading dataset from https://archive.materialscloud.org/record/2020.110\n",
    "\n",
    "!wget \"https://archive.materialscloud.org/record/file?file_id=b612d8e3-58af-4374-96ba-b3551ac5d2f4&filename=methane.extxyz.gz&record_id=528\" -O methane.extxyz.gz\n",
    "!gunzip -k methane.extxyz.gz\n",
    "\n",
    "import numpy as np\n",
    "import ase.io\n",
    "import tqdm\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "structures = ase.io.read('methane.extxyz', index='0:1000')\n",
    "\n",
    "HYPERS = {\n",
    "    'interaction_cutoff': 6.3,\n",
    "    'max_radial': 5,\n",
    "    'max_angular': 5,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.05,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO'\n",
    "}\n",
    "\n",
    "all_species = get_all_species(structures)\n",
    "\n",
    "coefficients = get_spherical_expansion(structures, HYPERS, all_species)\n",
    "coefficients = coefficients[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom class looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "class AdaptiveRidge:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        minimum = None\n",
    "        self.best_alpha_ = None\n",
    "        for alpha in np.logspace(-25, 10, 300):\n",
    "            regressor = Ridge(alpha=alpha, fit_intercept=False)\n",
    "            predictions = cross_val_predict(regressor, X, y)\n",
    "            now = np.mean((predictions - y)**2)\n",
    "            if (minimum is None) or (now < minimum):\n",
    "                minimum = now\n",
    "                self.best_alpha_ = alpha\n",
    "\n",
    "        self.ridge_ = Ridge(alpha=self.best_alpha_, fit_intercept=False)\n",
    "        self.ridge_.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.ridge_.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During fitting it estimates best value of regularization by cross validation using training data. There are additional methods get_params and set_params. These methods are required for sklearn.base.clone function. More details about it [here](https://scikit-learn.org/stable/developers/develop.html) (It is necessary to read only cloning section).  \n",
    "\n",
    "Let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import LinAlgWarning\n",
    "\n",
    "nice = StandardSequence([\n",
    "    StandardBlock(ThresholdExpansioner(50), None, IndividualLambdaPCAsBoth(20),\n",
    "                  ThresholdExpansioner(50, mode='invariants'), None, None),\n",
    "    StandardBlock(\n",
    "        ThresholdExpansioner(50),\n",
    "        CovariantsPurifierBoth(regressor=AdaptiveRidge(), max_take=20),\n",
    "        IndividualLambdaPCAsBoth(10),\n",
    "        ThresholdExpansioner(50, mode='invariants'),\n",
    "        InvariantsPurifier(regressor=AdaptiveRidge(), max_take=20),\n",
    "        InvariantsPCA(20)),\n",
    "])\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    # a lot of ill conditioned matrices with super small alpha\n",
    "    warnings.filterwarnings(\"ignore\", category=LinAlgWarning)\n",
    "    nice.fit(coefficients)\n",
    "\n",
    "res = nice.transform(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to access best alpha parameters for all paritiies and lambda chanels in the final model: \n",
    "\n",
    "(convenient getters might be added in the next version of NICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambd in range(6):\n",
    "    if (nice.blocks_[1].covariants_purifier_.even_purifier_.purifiers_[lambd]):\n",
    "        print(\"parity: even; lambda: {}; best alpha: {}\".format(\n",
    "            lambd, nice.blocks_[1].covariants_purifier_.even_purifier_.\n",
    "            purifiers_[lambd].regressor_.best_alpha_))\n",
    "    if (nice.blocks_[1].covariants_purifier_.odd_purifier_.purifiers_[lambd]):\n",
    "        print(\"parity odd; lambda: {}; best alpha: {}\".format(\n",
    "            lambd, nice.blocks_[1].covariants_purifier_.odd_purifier_.\n",
    "            purifiers_[lambd].regressor_.best_alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for InvariantsPurifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best alpha of invariants purifier: \",\n",
    "      nice.blocks_[1].invariants_purifier_.regressor_.best_alpha_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
